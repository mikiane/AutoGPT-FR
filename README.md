<!-- Auto-GPT : Une exp√©rience autonome avec GPT-4 -->

<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Auto-GPT : Une exp√©rience autonome avec GPT-4</title>
</head>
<body>
    <h1>Auto-GPT : Une exp√©rience autonome avec GPT-4</h1>
    <img src="https://img.shields.io/github/stars/Torantulino/auto-gpt?style=social" alt="√âtoiles du d√©p√¥t GitHub">
    <img src="https://img.shields.io/twitter/follow/siggravitas?style=social" alt="Suivre sur Twitter">
    <a href="https://discord.gg/PQ7VX6TY4t"><img src="https://dcbadge.vercel.app/api/server/PQ7VX6TY4t?style=flat" alt="Discord"></a>
    <a href="https://github.com/Torantulino/Auto-GPT/actions/workflows/unit_tests.yml"><img src="https://github.com/Torantulino/Auto-GPT/actions/workflows/unit_tests.yml/badge.svg" alt="Tests unitaires"></a>

Auto-GPT est une application open-source exp√©rimentale mettant en valeur les capacit√©s du mod√®le de langage GPT-4. Ce programme, pilot√© par GPT-4, relie les "pens√©es" LLM pour atteindre de mani√®re autonome l'objectif que vous avez d√©fini. En tant que l'un des premiers exemples de GPT-4 fonctionnant en totale autonomie, Auto-GPT repousse les limites de ce qui est possible avec l'IA.</p>

    



<p align="center">
 Development of this free, open-source project is made possible by all the <a href="https://github.com/Torantulino/Auto-GPT/graphs/contributors">contributors</a> and <a href="https://github.com/sponsors/Torantulino">sponsors</a>. If you'd like to sponsor this project and have your avatar or company logo appear below <a href="https://github.com/sponsors/Torantulino">click here</a>.

<h3 align="center">Individual Sponsors</h3>
<p align="center">
<a href="https://github.com/robinicus"><img src="https://github.com/robinicus.png" width="50px" alt="robinicus" /></a>&nbsp;&nbsp;<a href="https://github.com/prompthero"><img src="https://github.com/prompthero.png" width="50px" alt="prompthero" /></a>&nbsp;&nbsp;<a href="https://github.com/crizzler"><img src="https://github.com/crizzler.png" width="50px" alt="crizzler" /></a>&nbsp;&nbsp;<a href="https://github.com/tob-le-rone"><img src="https://github.com/tob-le-rone.png" width="50px" alt="tob-le-rone" /></a>&nbsp;&nbsp;<a href="https://github.com/FSTatSBS"><img src="https://github.com/FSTatSBS.png" width="50px" alt="FSTatSBS" /></a>&nbsp;&nbsp;<a href="https://github.com/toverly1"><img src="https://github.com/toverly1.png" width="50px" alt="toverly1" /></a>&nbsp;&nbsp;<a href="https://github.com/ddtarazona"><img src="https://github.com/ddtarazona.png" width="50px" alt="ddtarazona" /></a>&nbsp;&nbsp;<a href="https://github.com/Nalhos"><img src="https://github.com/Nalhos.png" width="50px" alt="Nalhos" /></a>&nbsp;&nbsp;<a href="https://github.com/Kazamario"><img src="https://github.com/Kazamario.png" width="50px" alt="Kazamario" /></a>&nbsp;&nbsp;<a href="https://github.com/pingbotan"><img src="https://github.com/pingbotan.png" width="50px" alt="pingbotan" /></a>&nbsp;&nbsp;<a href="https://github.com/indoor47"><img src="https://github.com/indoor47.png" width="50px" alt="indoor47" /></a>&nbsp;&nbsp;<a href="https://github.com/AuroraHolding"><img src="https://github.com/AuroraHolding.png" width="50px" alt="AuroraHolding" /></a>&nbsp;&nbsp;<a href="https://github.com/kreativai"><img src="https://github.com/kreativai.png" width="50px" alt="kreativai" /></a>&nbsp;&nbsp;<a href="https://github.com/hunteraraujo"><img src="https://github.com/hunteraraujo.png" width="50px" alt="hunteraraujo" /></a>&nbsp;&nbsp;<a href="https://github.com/Explorergt92"><img src="https://github.com/Explorergt92.png" width="50px" alt="Explorergt92" /></a>&nbsp;&nbsp;<a href="https://github.com/judegomila"><img src="https://github.com/judegomila.png" width="50px" alt="judegomila" /></a>&nbsp;&nbsp;
<a href="https://github.com/thepok"><img src="https://github.com/thepok.png" width="50px" alt="thepok" /></a>
&nbsp;&nbsp;<a href="https://github.com/SpacingLily"><img src="https://github.com/SpacingLily.png" width="50px" alt="SpacingLily" /></a>&nbsp;&nbsp;<a href="https://github.com/merwanehamadi"><img src="https://github.com/merwanehamadi.png" width="50px" alt="merwanehamadi" /></a>&nbsp;&nbsp;<a href="https://github.com/m"><img src="https://github.com/m.png" width="50px" alt="m" /></a>&nbsp;&nbsp;<a href="https://github.com/zkonduit"><img src="https://github.com/zkonduit.png" width="50px" alt="zkonduit" /></a>&nbsp;&nbsp;<a href="https://github.com/maxxflyer"><img src="https://github.com/maxxflyer.png" width="50px" alt="maxxflyer" /></a>&nbsp;&nbsp;<a href="https://github.com/tekelsey"><img src="https://github.com/tekelsey.png" width="50px" alt="tekelsey" /></a>&nbsp;&nbsp;<a href="https://github.com/digisomni"><img src="https://github.com/digisomni.png" width="50px" alt="digisomni" /></a>&nbsp;&nbsp;<a href="https://github.com/nocodeclarity"><img src="https://github.com/nocodeclarity.png" width="50px" alt="nocodeclarity" /></a>&nbsp;&nbsp;<a href="https://github.com/tjarmain"><img src="https://github.com/tjarmain.png" width="50px" alt="tjarmain" /></a>
</p>


## Table des mati√®res

- [Auto-GPT : une exp√©rience autonome GPT-4](#auto-gpt-une-exp√©rience-autonome-gpt-4)
  - [D√©monstration (30/03/2023) :](#d√©monstration-30032023)
  - [üíñ Aidez √† financer le d√©veloppement d'Auto-GPT](#-aidez-√†-financer-le-d√©veloppement-dauto-gpt)
  - [Table des mati√®res](#table-des-mati√®res)
  - [üöÄ Fonctionnalit√©s](#-fonctionnalit√©s)
  - [üìã Exigences](#-exigences)
  - [üíæ Installation](#-installation)
  - [üîß Utilisation](#-utilisation)
  - [üó£Ô∏è Mode vocal](#Ô∏è-mode-vocal)
  - [üîç Configuration des cl√©s API Google](#-configuration-des-cl√©s-api-google)
    - [Configuration des variables d'environnement](#configuration-des-variables-denvironnement)
  - [üíÄ Mode continu ‚ö†Ô∏è](#-mode-continu-Ô∏è)
  - [Mode GPT3.5 UNIQUEMENT](#mode-gpt35-uniquement)
  - [üñº G√©n√©ration d'images](#g√©n√©ration-dimages)
  - [‚ö†Ô∏è Limitations](#Ô∏è-limitations)
  - [üõ° Avertissement](#-avertissement)
  - [üê¶ Connectez-vous avec nous sur Twitter](#-connectez-vous-avec-nous-sur-twitter)


## üöÄ Fonctionnalit√©s
üåê Acc√®s √† Internet pour les recherches et la collecte d'informations
üíæ Gestion de la m√©moire √† court et long terme
üß† Instances GPT-4 pour la g√©n√©ration de texte
üîó Acc√®s aux sites Web et plateformes populaires
üóÉÔ∏è Stockage de fichiers et r√©sum√© avec GPT-3.5
üìã Exigences
Python 3.8 ou ult√©rieur
Cl√© API OpenAI
Cl√© API PINECONE
Optionnel :

Cl√© ElevenLabs (si vous voulez que l'IA parle)


## üíæ Installation
Pour installer Auto-GPT, suivez ces √©tapes :

Assurez-vous d'avoir toutes les exigences ci-dessus, sinon, installez/obtenez-les.
Les commandes suivantes doivent √™tre ex√©cut√©es dans une fen√™tre CMD, Bash ou Powershell. Pour ce faire, allez dans un dossier de votre ordinateur, cliquez sur le chemin du dossier en haut et tapez CMD, puis appuyez sur Entr√©e.



1. Clonez le d√©p√¥t :
Pour cette √©tape, vous avez besoin de Git install√©, mais vous pouvez simplement t√©l√©charger le fichier zip √† la place en cliquant sur le bouton en haut de cette page ‚òùÔ∏è

```
git clone https://github.com/Torantulino/Auto-GPT.git
```

2. Acc√©dez au r√©pertoire du projet :
(Tapez ceci dans votre fen√™tre CMD, votre objectif est de naviguer dans la fen√™tre CMD vers le d√©p√¥t que vous venez de t√©l√©charger)

```
cd 'Auto-GPT'
```

3. Installez les d√©pendances requises :
(L√† encore, tapez ceci dans votre fen√™tre CMD)

```
pip install -r requirements.txt
```

4. Renommez .env.template en .env et remplissez votre OPENAI_API_KEY. Si vous pr√©voyez d'utiliser le mode Speech, remplissez √©galement votre ELEVEN_LABS_API_KEY.
Obtenez votre cl√© API OpenAI depuis : https://platform.openai.com/account/api-keys.
Obtenez votre cl√© API ElevenLabs depuis : https://elevenlabs.io. Vous pouvez consulter votre xi-api-key en utilisant l'onglet "Profil" sur le site.
Si vous souhaitez utiliser GPT sur une instance Azure, d√©finissez USE_AZURE sur True et ensuite :
Renommez azure.yaml.template en azure.yaml et fournissez le azure_api_base, azure_api_version et tous les identifiants de d√©ploiement pour les mod√®les pertinents dans la section azure_model_map :
fast_llm_model_deployment_id - votre identifiant de d√©ploiement gpt-3.5-turbo ou gpt-4
smart_llm_model_deployment_id - votre identifiant de d√©ploiement gpt-4
embedding_model_deployment_id - votre identifiant de d√©ploiement text-embedding-ada-002 v2
Veuillez sp√©cifier toutes ces valeurs en tant que cha√Ænes de caract√®res entre guillemets doubles
Les d√©tails se trouvent ici : https://pypi.org/project/openai/ dans la section Microsoft Azure Endpoints et ici : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/tutorials/embeddings?tabs=command-line pour le mod√®le d'embedding.


## üîß Usage

1. Ex√©cutez le script Python `main.py` dans votre terminal :
   _(Tapez ceci dans votre fen√™tre CMD)_

```
python scripts/main.py
```

2. Apr√®s chaque action d'AUTO-GPT, tapez "NEXT COMMAND" pour l'autoriser √† continuer.
3. Pour quitter le programme, tapez "exit" et appuyez sur Entr√©e.

### Logs

Vous trouverez les journaux d'activit√© et d'erreur dans le dossier `./logs`

Pour produire des journaux de d√©bogage :

```
python scripts/main.py --debug
```

## üó£Ô∏è Mode vocal

Utilisez cette option pour utiliser le TTS pour l'Auto-GPT.

```
python scripts/main.py --speak
```

## üîç Configuration des cl√©s de l'API Google

Cette section est optionnelle, utilisez l'API officielle de Google si vous avez des probl√®mes avec l'erreur 429 lors d'une recherche Google.
Pour utiliser la commande `google_official_search`, vous devez configurer vos cl√©s API Google dans vos variables d'environnement.

1. Allez dans la [Google Cloud Console] (https://console.cloud.google.com/).
2. Si vous n'avez pas encore de compte, cr√©ez-en un et connectez-vous.
3. Cr√©ez un nouveau projet en cliquant sur le menu d√©roulant "Select a Project" en haut de la page et en cliquant sur "New Project". Donnez-lui un nom et cliquez sur "Cr√©er".
4. Allez sur le [tableau de bord APIs & Services] (https://console.cloud.google.com/apis/dashboard) et cliquez sur "Enable APIs and Services" (Activer les APIs et les services). Recherchez "Custom Search API" et cliquez dessus, puis cliquez sur "Enable".
5. Allez sur la page [Credentials](https://console.cloud.google.com/apis/credentials) et cliquez sur "Create Credentials". Choisissez "API Key".
6. Copiez la cl√© API et d√©finissez-la comme une variable d'environnement nomm√©e `GOOGLE_API_KEY` sur votre machine. Voir la configuration des variables d'environnement ci-dessous.
7. Allez sur la page [Moteur de recherche personnalis√©] (https://cse.google.com/cse/all) et cliquez sur "Ajouter".
8. Configurez votre moteur de recherche en suivant les instructions. Vous pouvez choisir d'effectuer une recherche sur l'ensemble du web ou sur des sites sp√©cifiques.
9. Une fois que vous avez cr√©√© votre moteur de recherche, cliquez sur "Panneau de configuration", puis sur "Bases". Copiez l'"ID du moteur de recherche" et d√©finissez-le comme une variable d'environnement nomm√©e `CUSTOM_SEARCH_ENGINE_ID` sur votre machine. Voir la configuration des variables d'environnement ci-dessous.

N'oubliez pas que votre quota quotidien gratuit de recherches personnalis√©es est limit√© √† 100 recherches. Pour augmenter cette limite, vous devez assigner un compte de facturation au projet afin de b√©n√©ficier d'un maximum de 10K recherches quotidiennes.

### Configuration des variables d'environnement

Pour les utilisateurs de Windows :
```
setx GOOGLE_API_KEY "YOUR_GOOGLE_API_KEY"
setx CUSTOM_SEARCH_ENGINE_ID "YOUR_CUSTOM_SEARCH_ENGINE_ID"

```

Pour les utilisateurs macOS & Linux :

```
export GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
export CUSTOM_SEARCH_ENGINE_ID="YOUR_CUSTOM_SEARCH_ENGINE_ID"

```

## Configuration de Redis

Installer docker desktop.

Ex√©cutez :

```
docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest
```

Voir https://hub.docker.com/r/redis/redis-stack-server pour la d√©finition d'un mot de passe et d'autres configurations.

D√©finissez les variables d'environnement suivantes :

```
MEMORY_BACKEND=redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
```

Notez que ceci n'est pas destin√© √† √™tre ex√©cut√© face √† l'internet et n'est pas s√©curis√©, n'exposez pas redis √† l'internet sans mot de passe ou m√™me vraiment sans mot de passe.

Vous pouvez optionnellement d√©finir

```
WIPE_REDIS_ON_START=False
```

Pour conserver la m√©moire stock√©e dans Redis.

Vous pouvez sp√©cifier l'indice de m√©moire pour Redis en proc√©dant comme suit :

```
MEMORY_INDEX=whatever
```

## üå≤ Configuration de la cl√© API Pinecone

Pinecone permet de stocker de grandes quantit√©s de m√©moire vectorielle, ce qui permet de charger uniquement les m√©moires pertinentes pour l'agent √† un moment donn√©.

1. Allez sur [pinecone](https://app.pinecone.io/) et cr√©ez un compte si vous n'en avez pas d√©j√† un.
2. Choisissez le plan `Starter` pour √©viter d'√™tre factur√©.
3. Trouvez votre cl√© API et votre r√©gion sous le projet par d√©faut dans la barre lat√©rale gauche.

### Configurer les variables d'environnement

Il suffit de les d√©finir dans le fichier `.env`.

Vous pouvez √©galement les d√©finir √† partir de la ligne de commande (avanc√©) :

Pour les utilisateurs de Windows :

```
setx PINECONE_API_KEY "VOTRE_PINECONE_API_KEY"
setx PINECONE_ENV "Votre r√©gion de pommes de pin" # quelque chose comme : us-east4-gcp

```

Pour les utilisateurs de macOS et de Linux :

```
export PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
export PINECONE_ENV="Votre r√©gion de pommes de pin" # quelque chose comme : us-east4-gcp

```


## Configurer votre type de cache

Par d√©faut, Auto-GPT va utiliser LocalCache au lieu de redis ou Pinecone.

Pour passer √† l'un ou l'autre, changez la variable env `MEMORY_BACKEND` √† la valeur que vous voulez :

`local` (par d√©faut) utilise un fichier de cache JSON local
`pinecone` utilise le compte Pinecone.io que vous avez configur√© dans vos param√®tres ENV
`redis` utilisera le cache redis que vous avez configur√©

## Voir l'utilisation de la m√©moire

1. Voir l'utilisation de la m√©moire en utilisant le drapeau `--debug` :)

## üíÄ Mode continu ‚ö†Ô∏è

Ex√©cuter l'IA **sans** l'autorisation de l'utilisateur, 100% automatis√©.
Le mode continu n'est pas recommand√©.
Il est potentiellement dangereux et peut faire tourner votre IA √† l'infini ou effectuer des actions que vous n'autoriseriez pas habituellement.
Utilisez-le √† vos risques et p√©rils.

1. Lancez le script Python `main.py` dans votre terminal :

```
python scripts/main.py --continuous

```

2. Pour quitter le programme, appuyez sur Ctrl + C

## Mode GPT3.5 ONLY

Si vous n'avez pas acc√®s √† l'api GPT4, ce mode vous permettra d'utiliser Auto-GPT !

```
python scripts/main.py --gpt3only
```

Il est recommand√© d'utiliser une machine virtuelle pour les t√¢ches qui n√©cessitent des mesures de s√©curit√© √©lev√©es afin d'√©viter tout dommage potentiel au syst√®me et aux donn√©es de l'ordinateur principal.

## üñº Image Generation

By default, Auto-GPT uses DALL-e for image generation. To use Stable Diffusion, a [HuggingFace API Token](https://huggingface.co/settings/tokens) is required.

Once you have a token, set these variables in your `.env`:

```
IMAGE_PROVIDER=sd
HUGGINGFACE_API_TOKEN="YOUR_HUGGINGFACE_API_TOKEN"
```

## ‚ö†Ô∏è Limites

Cette exp√©rience vise √† d√©montrer le potentiel de GPT-4, mais elle comporte certaines limites :

1. Il ne s'agit pas d'une application ou d'un produit fini, mais d'une exp√©rience.
2. Il se peut que les r√©sultats ne soient pas satisfaisants dans des sc√©narios commerciaux complexes et r√©els. En fait, si c'est le cas, veuillez partager vos r√©sultats !
3. Assez co√ªteux √† g√©rer, alors d√©finissez et surveillez les limites de votre cl√© API avec OpenAI !

## üõ° Avis de non-responsabilit√©

Avis de non-responsabilit√©
Ce projet, Auto-GPT, est une application exp√©rimentale et est fourni "tel quel" sans aucune garantie, expresse ou implicite. En utilisant ce logiciel, vous acceptez d'assumer tous les risques associ√©s √† son utilisation, y compris, mais sans s'y limiter, la perte de donn√©es, la d√©faillance du syst√®me ou tout autre probl√®me pouvant survenir.

Les d√©veloppeurs et les contributeurs de ce projet n'acceptent aucune responsabilit√© pour les pertes, dommages ou autres cons√©quences pouvant r√©sulter de l'utilisation de ce logiciel. Vous √™tes seul responsable de toutes les d√©cisions et actions prises sur la base des informations fournies par Auto-GPT.

**Veuillez noter que l'utilisation du mod√®le de langage GPT-4 peut √™tre co√ªteuse en raison de l'utilisation de jetons **En utilisant ce projet, vous reconnaissez que vous √™tes responsable du contr√¥le et de la gestion de votre propre utilisation de jetons et des co√ªts associ√©s. Il est fortement recommand√© de v√©rifier r√©guli√®rement votre utilisation de l'API OpenAI et de mettre en place toutes les limites ou alertes n√©cessaires pour √©viter des frais inattendus.

En tant qu'exp√©rience autonome, Auto-GPT peut g√©n√©rer du contenu ou prendre des mesures qui ne sont pas conformes aux pratiques commerciales du monde r√©el ou aux exigences l√©gales. Il est de votre responsabilit√© de vous assurer que toutes les actions ou d√©cisions prises sur la base des r√©sultats de ce logiciel sont conformes √† toutes les lois, r√©glementations et normes √©thiques applicables. Les d√©veloppeurs et les contributeurs de ce projet ne peuvent √™tre tenus responsables des cons√©quences de l'utilisation de ce logiciel.

En utilisant Auto-GPT, vous acceptez d'indemniser, de d√©fendre et de d√©gager de toute responsabilit√© les d√©veloppeurs, les contributeurs et toutes les parties affili√©es contre toute r√©clamation, tout dommage, toute perte, toute responsabilit√©, tout co√ªt et toute d√©pense (y compris les honoraires raisonnables d'avocat) r√©sultant de votre utilisation de ce logiciel ou de votre violation de ces conditions.

## üê¶ Connectez-vous avec nous sur Twitter

Restez au courant des derni√®res nouvelles, mises √† jour et r√©flexions sur Auto-GPT en suivant nos comptes Twitter. Engagez-vous avec le d√©veloppeur et le propre compte de l'IA pour des discussions int√©ressantes, des mises √† jour de projets, et plus encore.

- D√©veloppeur** : Suivez [@siggravitas] (https://twitter.com/siggravitas) pour obtenir des informations sur le processus de d√©veloppement, des mises √† jour sur le projet et des sujets connexes de la part du cr√©ateur de l'Entrepreneur-GPT.
- **Entrepreneur-GPT**: Join the conversation with the AI itself by following [@En_GPT](https://twitter.com/En_GPT). Share your experiences, discuss the AI's outputs, and engage with the growing community of users.

We look forward to connecting with you and hearing your thoughts, ideas, and experiences with Auto-GPT. Join us on Twitter and let's explore the future of AI together!

<p align="center">
  <a href="https://star-history.com/#Torantulino/auto-gpt&Date">
    <img src="https://api.star-history.com/svg?repos=Torantulino/auto-gpt&type=Date" alt="Star History Chart">
  </a>
</p>

## Run tests

To run tests, run the following command:

```
python -m unittest discover tests
```

Pour ex√©cuter les tests et voir la couverture, ex√©cutez la commande suivante : ``python -m unittest tests ``` :

```
coverage run -m unittest discover tests
```

## Ex√©cuter linter

Ce projet utilise [flake8](https://flake8.pycqa.org/en/latest/) pour le linting. Pour lancer le linter, ex√©cutez la commande suivante :

```
flake8 scripts/ tests/

# Ou, si vous voulez lancer flake8 avec la m√™me configuration que l'IC :
flake8 scripts/ tests/ --select E303,W293,W291,W292,E305
```